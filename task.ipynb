{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T14:51:50.025227Z",
     "start_time": "2024-12-18T14:51:37.714690Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Nukuta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nukuta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:07.924700Z",
     "start_time": "2024-12-18T14:57:07.921708Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "# Параметры чанков\n",
    "MAX_SENTENCES_PER_CHUNK = 5\n",
    "OVERLAP = 1"
   ],
   "id": "dc95a6f6a6d7fb3f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:10.991386Z",
     "start_time": "2024-12-18T14:57:10.797214Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"papers.csv\")"
   ],
   "id": "eb37dcd24b75618e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:11.439322Z",
     "start_time": "2024-12-18T14:57:11.435320Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text"
   ],
   "id": "46d4d31f9b3cd9c1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:12.679553Z",
     "start_time": "2024-12-18T14:57:12.280055Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"clean_text\"] = df[\"Текст статьи\"].apply(clean_text)"
   ],
   "id": "253eb9de204994be",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Разбиваю на чанки по предложениям с перекрытием"
   ],
   "id": "83a7c4b8e2c58603"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:13.980139Z",
     "start_time": "2024-12-18T14:57:13.975109Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk_text_by_sentences(text, max_sentences=5, overlap=1):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(sentences):\n",
    "        end = start + max_sentences\n",
    "        chunk_sents = sentences[start:end]\n",
    "        chunk_text = \" \".join(chunk_sents)\n",
    "        chunks.append(chunk_text)\n",
    "        new_start = end - overlap\n",
    "        if new_start <= start:\n",
    "            break\n",
    "        start = new_start\n",
    "    return chunks"
   ],
   "id": "7cdcec5334d6323c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:15.724967Z",
     "start_time": "2024-12-18T14:57:14.591396Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = []\n",
    "for idx, row in df.iterrows():\n",
    "    title = row[\"Заголовок\"]\n",
    "    text = row[\"clean_text\"]\n",
    "    text_chunks = chunk_text_by_sentences(text, max_sentences=MAX_SENTENCES_PER_CHUNK, overlap=OVERLAP)\n",
    "    for ch in text_chunks:\n",
    "        docs.append({\n",
    "            \"title\": title,\n",
    "            \"text_chunk\": ch\n",
    "        })"
   ],
   "id": "b990e62333652aca",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:30.573381Z",
     "start_time": "2024-12-18T14:57:30.566275Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "texts_for_embedding = [(d[\"title\"], d[\"text_chunk\"]) for d in docs]"
   ],
   "id": "84b5bbedc11d3c0e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:39.860572Z",
     "start_time": "2024-12-18T14:57:39.856254Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "texts_for_embedding[0]"
   ],
   "id": "278d8461164749fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Правильный способ обработки данных смешанного типа.Современные метрики расстояния.',\n",
       " 'Забавный факт: Scikit-learn не имеет никаких метрик расстояния, которые могут обрабатывать как категориальные, так и непрерывные данные!Как мы можем затем использовать алгоритмы кластеризации, например,K-NN, если у нас есть набор данных с переменными смешанного типа? Фото Феди Джейкоб на Unsplash Обновление (27/07/19) - пакет был выпущен в PYPI в качестве Distython.Я опубликовал статью, чтобы объяснить, как она работает. Большая проблема, с которой я столкнулся во время летней стажировки в ИТ-инновационном центре, была отсутствие существующих реализаций метрик дистанции, которые могли бы обрабатывать как данные смешанного типа, так и отсутствующие значения.Он начал мой долгий поиск алгоритмов, которые могут удовлетворить эти требования.Несколько исследовательских работ позже я обнаружил довольно интересные показатели дистанции, которые могут помочь повысить точность вашей модели машинного обучения при работе с данными смешанного типа, отсутствующими значениями или обоими.Я реализовал их в свободное время и опубликовал их реализацию кода на GitHub, чтобы вы могли легко использовать его с помощью Scikit-Learn.Но как?Я объясню это в этом уроке! Что мне нравится в науке о данных, так это то, что он привлекает многих единомышленников, которые увлечены ИИ и наукой данных.Вот почему я хотел бы связаться с вами в LinkedIn!Вы также можете оставить любые отзывы и вопросы через мой личный веб -сайт. Обзор гетерогенных показателей расстояния Фото Энни Спратт на Unsplash Прежде чем мы начнем, я хотел бы порекомендовать посмотреть на эту статью, если вы хотите получить более глубокое понимание алгоритмов, о которых я расскажу.Моя главная цель здесь - предоставить вам интуитивное понимание этих алгоритмов, чтобы вы могли использовать мою статью в качестве быстрых справочных листов.Вы можете найти практическую часть с кодом в конце статьи.Начнем!')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:30.139469Z",
     "start_time": "2024-12-18T15:00:29.725584Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "df_save = pd.DataFrame(texts_for_embedding, columns=[\"Title\", \"Text Chunk\"])\n",
    "df.to_csv(\"to_process.csv\", index=False, encoding='utf-8')"
   ],
   "id": "69e3574862d5a9f9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Далее я собираюсь пойти через генерацию вопросов к каждому чанку с помощью LLM. Из-за сжатых сроков воспользовался API chatgpt, чтобы получить к каждому чанку по 5 заголовков\n",
    "Скрипт приложен в архиве generate_questions.py"
   ],
   "id": "6006b9b89e092ffe"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Импортирую полученный файл"
   ],
   "id": "62d3eff706600a2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:48.849921Z",
     "start_time": "2024-12-18T15:00:47.968435Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"partial_results.csv\")"
   ],
   "id": "a526dfcdb58d9820",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:50.400139Z",
     "start_time": "2024-12-18T15:00:50.396962Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_question(q):\n",
    "    return q.strip()"
   ],
   "id": "a59aa5941ddc4295",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:00:50.792270Z",
     "start_time": "2024-12-18T15:00:50.779364Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"question_clean\"] = df[\"question\"].apply(clean_question)"
   ],
   "id": "9b6f08f23c6f91f1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Добавляю к новым вопросам текущие заголовки, чтобы в дальнейшем у одного чанка было 6 признаков"
   ],
   "id": "4752ff26a28be8d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:09:56.751640Z",
     "start_time": "2024-12-18T15:09:56.623614Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "df['question_clean'] = df['question'] \n",
    "\n",
    "new_rows = df[['title', 'chunk']].drop_duplicates().copy()\n",
    "new_rows['question'] = new_rows['title']  \n",
    "new_rows['question_clean'] = new_rows['title'] \n",
    "final_df = pd.concat([df, new_rows], ignore_index=True)"
   ],
   "id": "f98a430b261437a0",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Теперь есть датасет, разбитый на чанки, у каждого чанка есть 6 строк со списками вопросов к этому чанку."
   ],
   "id": "9cbd38b53c36a268"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:11:22.314845Z",
     "start_time": "2024-12-18T15:11:22.309570Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "questions = final_df[\"question_clean\"].tolist()"
   ],
   "id": "ef6b25b0f66e1557",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:14:14.855963Z",
     "start_time": "2024-12-18T15:14:14.835649Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_questions = [\n",
    "    q.split('. ', 1)[1] if '. ' in q else q for q in questions\n",
    "]"
   ],
   "id": "f3e6c32665223f69",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:41.004737Z",
     "start_time": "2024-12-18T15:14:26.406670Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "embeddings = model.encode(questions, show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True)"
   ],
   "id": "4c4907e56bf6e3da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/2095 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84ca157862404a389558cb50eb58e4d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:49.227154Z",
     "start_time": "2024-12-18T15:34:49.051129Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "np.save('embeddings_titles.npy', embeddings)"
   ],
   "id": "ba1da48629f7e729",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### Индекс для эмбеддингов"
   ],
   "id": "466eeed5e777a13f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:50.971993Z",
     "start_time": "2024-12-18T15:34:50.911285Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)"
   ],
   "id": "3b43dd8ea9d323cc",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:51.643133Z",
     "start_time": "2024-12-18T15:34:51.637602Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_top_k_embeddings(query, top_k=5):\n",
    "    q_vec = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    distances, indices = index.search(q_vec, top_k)\n",
    "    return [(int(idx_), float(distances[0][i])) for i, idx_ in enumerate(indices[0])]"
   ],
   "id": "b440ee3b32a797c",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:52.372560Z",
     "start_time": "2024-12-18T15:34:52.368735Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_embedding_score(query, doc_idx):\n",
    "    q_vec = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    doc_vec = embeddings[doc_idx].reshape(1, -1)\n",
    "    score = float((q_vec @ doc_vec.T)[0][0])\n",
    "    return score"
   ],
   "id": "5416a076aaf5c5b8",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### Матрица TF-IDF"
   ],
   "id": "e34a4a6d4015c8e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:54.164127Z",
     "start_time": "2024-12-18T15:34:53.274344Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(questions)"
   ],
   "id": "3265698b4eed51c",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:54.169726Z",
     "start_time": "2024-12-18T15:34:54.165138Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def retrieve_top_k_tfidf(query, top_k=5):\n",
    "    query_vec = tfidf_vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
    "    top_indices = np.argpartition(sims, -top_k)[-top_k:]\n",
    "    top_indices = top_indices[np.argsort(-sims[top_indices])]\n",
    "    return [(int(idx), float(sims[idx])) for idx in top_indices]"
   ],
   "id": "3034bbf8c3654c07",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:54.813936Z",
     "start_time": "2024-12-18T15:34:54.809880Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_tfidf_score(query, doc_idx):\n",
    "    query_vec = tfidf_vectorizer.transform([query])\n",
    "    doc_vec = tfidf_matrix[doc_idx]\n",
    "    sims = cosine_similarity(query_vec, doc_vec)[0][0]\n",
    "    return float(sims)"
   ],
   "id": "d59b2104d0dadccc",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### BM25"
   ],
   "id": "b6b432e7167729af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:56.148671Z",
     "start_time": "2024-12-18T15:34:55.687508Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "tokenized_questions = [q.split() for q in questions]\n",
    "bm25 = BM25Okapi(tokenized_questions)"
   ],
   "id": "508d1ded9b017465",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:56.154221Z",
     "start_time": "2024-12-18T15:34:56.149679Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_top_k_bm25(query, top_k=5):\n",
    "    tokenized_query = query.split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    top_indices = np.argpartition(scores, -top_k)[-top_k:]\n",
    "    top_indices = top_indices[np.argsort(-scores[top_indices])]\n",
    "    return [(int(idx), float(scores[idx])) for idx in top_indices]"
   ],
   "id": "247c7ce597755af9",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T15:34:56.583360Z",
     "start_time": "2024-12-18T15:34:56.578995Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_bm25_score(query, doc_idx):\n",
    "    tokenized_query = query.split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    return float(scores[doc_idx])"
   ],
   "id": "86131bacb3c3d987",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:34:00.226066Z",
     "start_time": "2024-12-18T16:34:00.221034Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_ensemble(query, top_k=5):\n",
    "    # Получаем топ-5 от каждого метода\n",
    "    emb_results = retrieve_top_k_embeddings(query, top_k=top_k)\n",
    "    tfidf_results = retrieve_top_k_tfidf(query, top_k=top_k)\n",
    "    bm25_results = retrieve_top_k_bm25(query, top_k=top_k)\n",
    "\n",
    "    # Собираем все индексы\n",
    "    candidate_indices = set([x[0] for x in emb_results] + [x[0] for x in tfidf_results] + [x[0] for x in bm25_results])\n",
    "\n",
    "    # Для каждого кандидата считаем все три скоринга\n",
    "    final_results = []\n",
    "    for idx_ in candidate_indices:\n",
    "        emb_score = compute_embedding_score(query, idx_)\n",
    "        tfidf_score = compute_tfidf_score(query, idx_)\n",
    "        bm25_score = compute_bm25_score(query, idx_)\n",
    "\n",
    "        tfidf_weight = 1.0\n",
    "        emb_weight = 1.0\n",
    "        final_score = (emb_score * emb_weight + tfidf_score * tfidf_weight + bm25_score) / (emb_weight + tfidf_weight + 1)\n",
    "        final_results.append((idx_, final_score, emb_score, tfidf_score, bm25_score))\n",
    "\n",
    "    final_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return final_results"
   ],
   "id": "5171b4263e134cee",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:33:31.975277Z",
     "start_time": "2024-12-18T16:33:31.969893Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_all_chunks_for_user_question(user_query, top_k=5):\n",
    "    ensemble_results = retrieve_ensemble(user_query, top_k=top_k)\n",
    "    candidates = []\n",
    "\n",
    "    for r in ensemble_results:\n",
    "        doc_idx, final_score, emb_s, tfidf_s, bm25_s = r\n",
    "\n",
    "        title = final_df.iloc[doc_idx][\"title\"]\n",
    "        chunk = final_df.iloc[doc_idx][\"chunk\"]\n",
    "        question = final_df.iloc[doc_idx][\"question\"]\n",
    "\n",
    "        candidates.append({\n",
    "            \"doc_idx\": doc_idx,\n",
    "            \"final_score\": final_score,\n",
    "            \"emb_score\": emb_s,\n",
    "            \"tfidf_score\": tfidf_s,\n",
    "            \"bm25_score\": bm25_s,\n",
    "            \"title\": title,\n",
    "            \"chunk\": chunk,\n",
    "            \"question\": question\n",
    "        })\n",
    "    sorted_candidates = sorted(candidates, key=lambda x: x[\"final_score\"], reverse=True)\n",
    "\n",
    "    return sorted_candidates[:top_k]"
   ],
   "id": "916a2998ce35d873",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:30:00.807229Z",
     "start_time": "2024-12-18T16:29:59.536968Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "user_query = \"Что такое обучение с подкреплением?\"\n",
    "top_k = 3\n",
    "\n",
    "all_candidates = get_all_chunks_for_user_question(user_query, top_k=top_k)\n",
    "\n",
    "print(\"\\nВсе кандидаты после ансамблирования:\")\n",
    "for candidate in all_candidates:\n",
    "    print(f\"doc_idx={candidate['doc_idx']}, final_score={candidate['final_score']:.4f}, \"\n",
    "          f\"emb = {candidate['emb_score']:.4f}, tfidf={candidate['tfidf_score']:.4f}, bm25={candidate['bm25_score']:.4f}\")\n",
    "    print(f\"Похожий вопрос: {candidate['question']}\")\n",
    "    print(f\"Статья: {candidate['title']}\")\n",
    "    print(f\"Соответствующий чанк: {candidate['chunk']}\")\n",
    "    print(\"-\" * 80)"
   ],
   "id": "8fc050105edd7b24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Все кандидаты после ансамблирования:\n",
      "doc_idx=55786, final_score=0.9973, emb = 0.7316, tfidf=0.6003, bm25=17.5623\n",
      "Похожий вопрос: 2. Что такое возврат в контексте обучения с подкреплением?\n",
      "Статья: Подкрепление обучения: процесс назначения Марков (часть 1)\n",
      "Соответствующий чанк: Награда и возвращение Награды - это численные значения, которые агент получает при выполнении какого -либо действия в некоторых штатах в окружающей среде.Числовое значение может быть положительным или отрицательным в зависимости от действий агента.В обучении подкрепления мы заботимся о максимизации совокупного вознаграждения (все агент по вознаграждению получает из окружающей среды) Вместо того, чтобы агент вознаграждения получает от текущего состояния (также называемого немедленным вознаграждением).Эта общая сумма вознаграждения, которую агент получает из окружающей среды, называется возвратами. Мы можем определить возврат как: Возврат (полное вознаграждение от окружающей среды) R [T+1] - это вознаграждение, полученное агентом на временном шаге T [0], выполняя действие (а), чтобы перейти из одного состояния в другое.Точно так же R [T+2] является вознаграждением, полученной агентом на временном шаге T [1], выполняя действие, чтобы перейти в другое состояние.И R [T] - награда, полученная агентом на последнее время, выполняя действие, чтобы перейти в другое состояние. Эпизодические и непрерывные задачи Эпизодические задачи: это задачи, которые имеют терминальное состояние (конечное состояние). Мы можем сказать, что у них есть конечные состояния.Например, в гоночных играх мы начинаем игру (начинать гонку) и играем в нее, пока игра не закончится (гонка заканчивается! ).Это называется эпизодом.Как только мы перезагружаем игру, она начнется с начального состояния, и, следовательно, каждый эпизод будет независим.Непрерывные задачи: это задачи, у которых нет концов, т. Е. У них нет никаких терминальных состояний.\n",
      "--------------------------------------------------------------------------------\n",
      "doc_idx=27000, final_score=0.9641, emb = 0.7002, tfidf=0.7683, bm25=12.4606\n",
      "Похожий вопрос: 1. Что такое обучение с подкреплением и какова его основная цель?\n",
      "Статья: Скользить в модель на основе моделей\n",
      "Соответствующий чанк: Ваш план состоит в том, чтобы отправить вам эту программу через легкие волны в будущем. Чтобы разработать эту программу, вам нужно знать что -то, называемое подкреплением обучения. В обучении подкрепления есть агент, который взаимодействует с окружающей средой. Мы моделируем взаимодействие агента с средой, основанной на математической структуре, называемой процессом принятия решений Маркова (MDP). Каждый агент начинается в государстве «X» и на каждом временном шаге предпринимает действие «А», получает вознаграждение «R» и приземляется в следующем состоянии «XT+1», и этот цикл повторяется, пока агент не достигнетЦелевое состояние «x`».\n",
      "--------------------------------------------------------------------------------\n",
      "doc_idx=27002, final_score=0.7569, emb = 0.5784, tfidf=0.3977, bm25=14.2011\n",
      "Похожий вопрос: 3. Что такое процесс принятия решений Маркова (MDP) и как он связан с обучением с подкреплением?\n",
      "Статья: Скользить в модель на основе моделей\n",
      "Соответствующий чанк: Ваш план состоит в том, чтобы отправить вам эту программу через легкие волны в будущем. Чтобы разработать эту программу, вам нужно знать что -то, называемое подкреплением обучения. В обучении подкрепления есть агент, который взаимодействует с окружающей средой. Мы моделируем взаимодействие агента с средой, основанной на математической структуре, называемой процессом принятия решений Маркова (MDP). Каждый агент начинается в государстве «X» и на каждом временном шаге предпринимает действие «А», получает вознаграждение «R» и приземляется в следующем состоянии «XT+1», и этот цикл повторяется, пока агент не достигнетЦелевое состояние «x`».\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Evaluation"
   ],
   "id": "bcbbdb89359988f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:30:01.477231Z",
     "start_time": "2024-12-18T16:30:00.808234Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(\"KirrAno93/rubert-base-cased-finetuned-squad\")\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"KirrAno93/rubert-base-cased-finetuned-squad\")\n",
    "qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer)"
   ],
   "id": "6a9038306412822d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:30:01.482621Z",
     "start_time": "2024-12-18T16:30:01.478267Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_answer(question, top_docs):\n",
    "    context = \" \".join([doc[\"chunk\"] for doc in top_docs])\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result[\"answer\"]"
   ],
   "id": "4f9d6474b3349429",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:34:12.368180Z",
     "start_time": "2024-12-18T16:34:04.497890Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "source": [
    "question = [\"Для чего можно использовать сверточные нейронные сети?\",\n",
    "            \"Что такое обучение с подкреплением?\",\n",
    "            \"Как развернуть модель машинного обучения?\",\n",
    "            \"Как написать алгоритм случайного леса?\"]\n",
    "top_k = 4\n",
    "for q in question:\n",
    "    all_candidates = get_all_chunks_for_user_question(q, top_k=top_k)\n",
    "    #print(all_candidates)\n",
    "    answer = generate_answer(q, all_candidates)\n",
    "    print(f\"Вопрос: {q} \\nОтвет на вопрос: {answer} \\n\\n\")\n"
   ],
   "id": "307231074d1c74d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Для чего можно использовать сверточные нейронные сети? \n",
      "Ответ на вопрос: для классификации образцов на несколько уникальных классов \n",
      "\n",
      "\n",
      "Вопрос: Что такое обучение с подкреплением? \n",
      "Ответ на вопрос: агент, который взаимодействует с окружающей средой \n",
      "\n",
      "\n",
      "Вопрос: Как развернуть модель машинного обучения? \n",
      "Ответ на вопрос: в конечной точке \n",
      "\n",
      "\n",
      "Вопрос: Как написать алгоритм случайного леса? \n",
      "Ответ на вопрос: вы можете предоставить диапазон для количества деревьев между 10 и 50 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Для улучшения сделал бы еще ансамбль поиска не только в заголовках, но и в текстах. Пробовал просто поиск по текстовым чанкам, получалось хуже, но если по заголовкам находить целый текст, вероятно, будет лучше"
   ],
   "id": "2aaa7784a9bb2a25"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [],
   "id": "d650a761a591572"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [],
   "id": "2d5c2c01299233fb"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [],
   "id": "3a00d1f1d98712da"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 143,
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# model_path = \"PleiAs\"\n",
    " # qa_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# qa_model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)"
   ],
   "id": "7be9501e8be9addf"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 144,
   "source": [
    "# def generate_answer_from_summaries(context, query, tokenizer, model):\n",
    "#     prompt = f\"Ответь на вопрос, опираясь на контекст, если в контексте нет ответа на вопрос, отвечай не знаю :\\n\\nContext: {context}\\n\\nВопрос: {query}\\nОтвет:\"\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "#     inputs.pop(\"token_type_ids\", None) \n",
    "#     output = model.generate(**inputs, max_length=1000, num_return_sequences=1)\n",
    "# \n",
    "#     return tokenizer.decode(output[0], skip_special_tokens=True)"
   ],
   "id": "28c390bc06a17cba"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ответ на вопрос: Ответь на вопрос, опираясь на контекст, если в контексте нет ответа на вопрос, отвечай не знаю :\n",
      "\n",
      "Context: Этот код создает случайный поиск для определения лучших параметров для случайного леса для выполнения своих классификаций. В следующем коде используется приведенный выше обычный поиск в сетке, запускает 100 различных комбинаций моделей и идентифицирует лучший. Это лучшие параметры: {‘N_estimators’: 266, ‘min_samples_split’: 5, ‘min_samples_leaf’: 1, «max_features’: «sqrt», «max_depth»: 30, «bootstrap»: true} Используя лучшую возможную модель случайного леса, мы достигаем точности 68,97%. Этот балл находится на одном уровне с результатами логистической регрессии и работает хуже, чем KNN. На мой взгляд, наиболее полезный результат случайного леса - это важность особенности.\n",
      "\n",
      "Вы можете запустить каждый из экспериментов параллельно. Минусы: вычислительно дорогие, так как строится так много моделей. Если конкретный гиперпараметр не важен, вы излишне исследуете различные возможности. Случайный поиск Вы указываете диапазоны или параметры для каждого гиперпараметра, и выбираются случайные значения каждого. Продолжая примером случайного леса, вы можете предоставить диапазон для количества деревьев между 10 и 50, а MAX_DEPTH - либо без ограничения, 10 или 20.\n",
      "\n",
      "Вы будете классифицированы в эту группу. Взят отсюда Деревья хорошо работают с данными, которые мы используем для обучения, но они не работают хорошо, когда дело доходит до новых образцов данных. К счастью, у нас есть случайный лес, который представляет собой сочетание многих деревьев решений с гибкостью, следовательно, приводит к повышению точности. Здесь я не буду слишком много внимания подробно о RF, потому что есть различные источники снаружи, мы можем понять, в чем стоит математика. Вот один из них.\n",
      "\n",
      "Вопрос: Как написать алгоритм случайного леса?\n",
      "Ответ: Этот алгоритм был создан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев» (RF) и был разработан в рамках проекта «Классификация случайных деревьев»\n"
     ]
    }
   ],
   "execution_count": 145,
   "source": [
    "# question = \"Как написать алгоритм случайного леса?\"\n",
    "# all_candidates = get_all_chunks_for_user_question(question, top_k=top_k)\n",
    "# context = \"\\n\\n\".join([doc[\"chunk\"] for doc in all_candidates])\n",
    "# \n",
    "# response = generate_answer_from_summaries(context, question, qa_tokenizer, qa_model)\n",
    "# print(f\"\\nОтвет на вопрос: {response}\")"
   ],
   "id": "ad5bf2b22087a1a1"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "15d1001aa7c579f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}